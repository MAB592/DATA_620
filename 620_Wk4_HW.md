### Week 4: Project 1 dataset description
#### Daina Bouquin

For project 1, we will be asked to:
a. Identify and load a network dataset that has some categorical information available for each node.   
b. For each of the nodes in the dataset, calculate degree centrality and eigenvector centrality.   
c. Compare your centrality measures across your categorical groups.   
    
To do this, I will build a dataset using the [NASA Astrophysics Data System](https://ui.adsabs.harvard.edu/) (SAO/NASA ADS) API; python modules: Pandas, NetworkX, and CSV; and [Neo4j](https://neo4j.com/). 
   
I will create an API query on a given topic (e.g. "Dark Energy") and extract metadata on the 50 most cited articles on that topic from ADS. I will aggregate and re-structure that metadata including the following elements for each article:   
+Number of authors   
+Author Names   
+Paper Title   
+Journal Title   
   
I will build a network structure wherein individual papers are the primary nodes, and authors are associated with them (authorship as edges). In this way we will be able to examine co-authorship networks on a given topic. The categorical variable I will use will be the journal titles -- the most cited articles come from only a small subset of astrophysics journals.
   
My hope is then to compare various centrality measures across journals to better understand collaborations among scientists on highly cited papers on a given topic.   
    
I will be working with John DeBlase to execute this plan for project 1.